{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25011044",
   "metadata": {},
   "source": [
    "# Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d859f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\AI projects\\bati-bank-credit-scoring\\venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:177: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance.\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))  # if notebook is in a subfolder\n",
    "# or\n",
    "sys.path.append(os.path.abspath(\".\"))  # if notebook is in project root\n",
    "\n",
    "from src.task_5.data_split import split_data\n",
    "from src.task_5.model_factory import get_models\n",
    "from src.task_5.train import train_and_log_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bde8f1",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35bf17b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded. Shape: (95662, 56)\n",
      "------------------------------\n",
      "NaN count in 'is_high_risk': 0\n",
      "Unique non-NaN values in 'is_high_risk': [-0.36093702  2.77056645]\n",
      "\n",
      "Mapping used: {np.float64(-0.3609370206423462): 0, np.float64(2.7705664501256675): 1}\n",
      "\n",
      "Value counts after re-mapping 'is_high_risk':\n",
      "is_high_risk\n",
      "0    84636\n",
      "1    11026\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/clean_data.csv\")\n",
    "\n",
    "# Assuming this is your data loading cell\n",
    "# ... (imports) ...\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Data Loaded. Shape: {df.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. Check for Target Column Presence and Type ---\n",
    "TARGET = \"is_high_risk\"\n",
    "\n",
    "if TARGET not in df.columns:\n",
    "    # CRITICAL CHECK: Does the column exist?\n",
    "    print(f\"FATAL ERROR: Column '{TARGET}' not found in DataFrame.\")\n",
    "    print(f\"Available columns: {df.columns.tolist()}\")\n",
    "    raise KeyError(\"Missing target column.\")\n",
    "\n",
    "# --- 3. Check for Nulls/NaNs in the Target Column ---\n",
    "target_nan_count = df[TARGET].isnull().sum()\n",
    "print(f\"NaN count in '{TARGET}': {target_nan_count}\")\n",
    "\n",
    "if target_nan_count == len(df):\n",
    "    # CRITICAL CHECK: Is the entire column empty (NaN)?\n",
    "    print(\"FATAL ERROR: Target column is entirely NaN. Check CSV encoding or preprocessing step.\")\n",
    "    raise ValueError(\"Target column is all null.\")\n",
    "\n",
    "# --- 4. Identify Unique Values (This is where your previous error occurred) ---\n",
    "unique_targets = df[TARGET].unique()\n",
    "\n",
    "# Filter out NaNs before checking length, just in case\n",
    "valid_unique_targets = df[TARGET].dropna().unique()\n",
    "\n",
    "print(f\"Unique non-NaN values in '{TARGET}': {valid_unique_targets}\")\n",
    "\n",
    "if len(valid_unique_targets) != 2:\n",
    "    print(f\"ERROR: Expected 2 unique values, found {len(valid_unique_targets)}.\")\n",
    "    print(\"The error is likely due to the column being read as an object type (string) or having too many zeros/near-zero values.\")\n",
    "    \n",
    "    # Check the data type of the target column\n",
    "    print(f\"Dtype of '{TARGET}': {df[TARGET].dtype}\")\n",
    "    \n",
    "    # If the dtype is 'object', try converting it to numeric:\n",
    "    if df[TARGET].dtype == 'object':\n",
    "         df[TARGET] = pd.to_numeric(df[TARGET], errors='coerce')\n",
    "         valid_unique_targets = df[TARGET].dropna().unique()\n",
    "         print(f\"After coercion, unique values: {valid_unique_targets}\")\n",
    "         if len(valid_unique_targets) != 2:\n",
    "             raise ValueError(\"Failed to isolate 2 scaled target values.\")\n",
    "    else:\n",
    "        # If it's already numeric but the unique list is empty/wrong, the data itself is flawed.\n",
    "        raise ValueError(\"Target column data quality issue.\")\n",
    "\n",
    "\n",
    "# --- 5. Re-mapping Logic (Only run if the checks above pass) ---\n",
    "\n",
    "sorted_targets = sorted(valid_unique_targets)\n",
    "scaled_to_binary_map = {\n",
    "    sorted_targets[0]: 0,\n",
    "    sorted_targets[1]: 1\n",
    "}\n",
    "print(f\"\\nMapping used: {scaled_to_binary_map}\")\n",
    "\n",
    "df[TARGET] = df[TARGET].map(scaled_to_binary_map)\n",
    "\n",
    "print(f\"\\nValue counts after re-mapping '{TARGET}':\")\n",
    "print(df[TARGET].value_counts(dropna=False))\n",
    "\n",
    "# Now proceed to split_data(df, target=TARGET)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5972d4",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee907b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target column is successfully re-mapped to integer classes (0, 1).\n",
      "------------------------------\n",
      "--- 6. Splitting Data for Training and Testing ---\n",
      "Data Split Success:\n",
      "X_train shape: (76529, 55)\n",
      "X_test shape: (19133, 55)\n",
      "Target split (Train 1s): 11.53%\n",
      "Target split (Test 1s): 11.52%\n"
     ]
    }
   ],
   "source": [
    "# --- CONTINUE HERE ---\n",
    "\n",
    "# 4. (Continued) Re-mapping Logic is complete and successful.\n",
    "print(f\"\\nTarget column is successfully re-mapped to integer classes (0, 1).\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 6. Data Split (Proceeding from the successful data preparation)\n",
    "print(\"--- 6. Splitting Data for Training and Testing ---\")\n",
    "\n",
    "# Assuming your split_data utility function is available and correctly imported:\n",
    "from src.task_5.data_split import split_data  # Ensure this import points to your utility file\n",
    "\n",
    "TARGET = \"is_high_risk\"\n",
    "# Use the utility function to split the data\n",
    "X_train, X_test, y_train, y_test = split_data(df.copy(), target=TARGET)\n",
    "\n",
    "print(f\"Data Split Success:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Target split (Train 1s): {y_train.sum() / len(y_train) * 100:.2f}%\")\n",
    "print(f\"Target split (Test 1s): {y_test.sum() / len(y_test) * 100:.2f}%\")\n",
    "\n",
    "# The data is now prepared. Proceed to call your training functions.\n",
    "# Example:\n",
    "# from src.train_models import train_and_track_model\n",
    "# logreg_metrics, _ = train_and_track_model(model_name='LogisticRegression', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a90bf9",
   "metadata": {},
   "source": [
    "# Load Models Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf251a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'model': LogisticRegression(random_state=42, solver='liblinear'),\n",
       "  'search': 'grid',\n",
       "  'params': {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}},\n",
       " 'DecisionTree': {'model': DecisionTreeClassifier(random_state=42),\n",
       "  'search': 'grid',\n",
       "  'params': {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10]}},\n",
       " 'RandomForest': {'model': RandomForestClassifier(random_state=42),\n",
       "  'search': 'random',\n",
       "  'params': {'n_estimators': [100, 200, 300], 'max_depth': [5, 10, None]}},\n",
       " 'GradientBoosting': {'model': GradientBoostingClassifier(random_state=42),\n",
       "  'search': 'random',\n",
       "  'params': {'n_estimators': [100, 200],\n",
       "   'learning_rate': [0.01, 0.1],\n",
       "   'max_depth': [3, 5]}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = get_models()\n",
    "models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2a085",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "990c2bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\AI projects\\bati-bank-credit-scoring\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "2025/12/16 17:12:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved locally at: c:\\Users\\hp\\Desktop\\AI projects\\bati-bank-credit-scoring\\models\\LogisticRegression_20251216_171228.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\AI projects\\bati-bank-credit-scoring\\venv\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\utils.py:215: FutureWarning: The filesystem model registry backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance.\n",
      "  return FileStore(store_uri)\n",
      "Successfully registered model 'credit_risk_model'.\n",
      "Created version '1' of model 'credit_risk_model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.884858621230335,\n",
       " 'precision': 0.525,\n",
       " 'recall': 0.009523809523809525,\n",
       " 'f1': 0.018708240534521157,\n",
       " 'roc_auc': 0.5879506615185457}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_config = models[\"LogisticRegression\"]\n",
    "\n",
    "logistic_results = train_and_log_model(\n",
    "    model_name=\"LogisticRegression\",\n",
    "    model_config=logistic_config,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    # experiment_name=\"Credit_Risk_Task5\"\n",
    ")\n",
    "\n",
    "logistic_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f961adfb",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59d0091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/16 17:16:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved locally at: c:\\Users\\hp\\Desktop\\AI projects\\bati-bank-credit-scoring\\models\\DecisionTree_20251216_171628.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'credit_risk_model' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'credit_risk_model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8855903412951445,\n",
       " 'precision': 0.5851063829787234,\n",
       " 'recall': 0.024943310657596373,\n",
       " 'f1': 0.04784688995215311,\n",
       " 'roc_auc': 0.6120003113091489}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_config = models[\"DecisionTree\"]\n",
    "\n",
    "decision_tree_results = train_and_log_model(\n",
    "    model_name=\"DecisionTree\",\n",
    "    model_config=dt_config,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    # experiment_name=\"Credit_Risk_Task5\"\n",
    ")\n",
    "\n",
    "decision_tree_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9443a6",
   "metadata": {},
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "595896fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\AI projects\\bati-bank-credit-scoring\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:324: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "2025/12/16 17:19:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'credit_risk_model' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'credit_risk_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved locally at: c:\\Users\\hp\\Desktop\\AI projects\\bati-bank-credit-scoring\\models\\RandomForest_20251216_171930.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8842314326033555,\n",
       " 'precision': 0.47282608695652173,\n",
       " 'recall': 0.03945578231292517,\n",
       " 'f1': 0.07283382168271244,\n",
       " 'roc_auc': 0.6411550560677958}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_config = models[\"RandomForest\"]\n",
    "\n",
    "random_forest_results = train_and_log_model(\n",
    "    model_name=\"RandomForest\",\n",
    "    model_config=rf_config,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    # experiment_name=\"Credit_Risk_Task5\"\n",
    ")\n",
    "\n",
    "random_forest_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023fbd2c",
   "metadata": {},
   "source": [
    "# Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44495a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\AI projects\\bati-bank-credit-scoring\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:324: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "2025/12/17 11:08:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'credit_risk_model' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved locally at: c:\\Users\\hp\\Desktop\\AI projects\\bati-bank-credit-scoring\\models\\GradientBoosting_20251217_110832.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '4' of model 'credit_risk_model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8859562013275493,\n",
       " 'precision': 0.5950413223140496,\n",
       " 'recall': 0.0326530612244898,\n",
       " 'f1': 0.061908856405846945,\n",
       " 'roc_auc': 0.6527416503778575}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_config = models[\"GradientBoosting\"]\n",
    "\n",
    "xgboost_results = train_and_log_model(\n",
    "    model_name=\"GradientBoosting\",\n",
    "    model_config=xgb_config,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    # experiment_name=\"Credit_Risk_Task5\"\n",
    ")\n",
    "\n",
    "xgboost_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822bb3d",
   "metadata": {},
   "source": [
    "# Compare All Models (Manual Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "752ae263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.885956</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.032653</td>\n",
       "      <td>0.061909</td>\n",
       "      <td>0.652742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.884231</td>\n",
       "      <td>0.472826</td>\n",
       "      <td>0.039456</td>\n",
       "      <td>0.072834</td>\n",
       "      <td>0.641155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.885590</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.024943</td>\n",
       "      <td>0.047847</td>\n",
       "      <td>0.612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.884859</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.587951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  precision    recall        f1   roc_auc\n",
       "XGBoost             0.885956   0.595041  0.032653  0.061909  0.652742\n",
       "RandomForest        0.884231   0.472826  0.039456  0.072834  0.641155\n",
       "DecisionTree        0.885590   0.585106  0.024943  0.047847  0.612000\n",
       "LogisticRegression  0.884859   0.525000  0.009524  0.018708  0.587951"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame.from_dict({\n",
    "    \"LogisticRegression\": logistic_results,\n",
    "    \"DecisionTree\": decision_tree_results,\n",
    "    \"RandomForest\": random_forest_results,\n",
    "    \"XGBoost\": xgboost_results\n",
    "}, orient=\"index\")\n",
    "\n",
    "results_df.sort_values(\"roc_auc\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694790e0",
   "metadata": {},
   "source": [
    "# Identify Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25201e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XGBoost'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_name = results_df[\"roc_auc\"].idxmax()\n",
    "best_model_name\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
